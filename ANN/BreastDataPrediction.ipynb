{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Breast.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "del data['Unnamed: 32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 2:].values\n",
    "y = data.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "y = labelencoder_X_1.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)\n",
    "\n",
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aarushi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=30, units=16, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Aarushi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aarushi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim=16, init='uniform', activation='relu', input_dim=30))\n",
    "# Adding dropout to prevent overfitting\n",
    "classifier.add(Dropout(p=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aarushi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=16, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\Aarushi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim=16, init='uniform', activation='relu'))\n",
    "# Adding dropout to prevent overfitting\n",
    "classifier.add(Dropout(p=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aarushi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim=1, init='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aarushi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Aarushi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/150\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 0.6922 - accuracy: 0.7617\n",
      "Epoch 2/150\n",
      "512/512 [==============================] - 0s 64us/step - loss: 0.6892 - accuracy: 0.7148\n",
      "Epoch 3/150\n",
      "512/512 [==============================] - 0s 55us/step - loss: 0.6848 - accuracy: 0.7871\n",
      "Epoch 4/150\n",
      "512/512 [==============================] - 0s 66us/step - loss: 0.6779 - accuracy: 0.8594\n",
      "Epoch 5/150\n",
      "512/512 [==============================] - 0s 61us/step - loss: 0.6677 - accuracy: 0.9121\n",
      "Epoch 6/150\n",
      "512/512 [==============================] - 0s 53us/step - loss: 0.6516 - accuracy: 0.9238\n",
      "Epoch 7/150\n",
      "512/512 [==============================] - 0s 67us/step - loss: 0.6293 - accuracy: 0.9414\n",
      "Epoch 8/150\n",
      "512/512 [==============================] - 0s 51us/step - loss: 0.5983 - accuracy: 0.9434\n",
      "Epoch 9/150\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.5607 - accuracy: 0.9453\n",
      "Epoch 10/150\n",
      "512/512 [==============================] - 0s 52us/step - loss: 0.5118 - accuracy: 0.9414\n",
      "Epoch 11/150\n",
      "512/512 [==============================] - 0s 51us/step - loss: 0.4591 - accuracy: 0.9473\n",
      "Epoch 12/150\n",
      "512/512 [==============================] - 0s 52us/step - loss: 0.4038 - accuracy: 0.9434\n",
      "Epoch 13/150\n",
      "512/512 [==============================] - 0s 55us/step - loss: 0.3469 - accuracy: 0.9434\n",
      "Epoch 14/150\n",
      "512/512 [==============================] - 0s 57us/step - loss: 0.2977 - accuracy: 0.9492\n",
      "Epoch 15/150\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.2579 - accuracy: 0.9531\n",
      "Epoch 16/150\n",
      "512/512 [==============================] - 0s 61us/step - loss: 0.2246 - accuracy: 0.9551\n",
      "Epoch 17/150\n",
      "512/512 [==============================] - 0s 63us/step - loss: 0.1983 - accuracy: 0.9551\n",
      "Epoch 18/150\n",
      "512/512 [==============================] - 0s 55us/step - loss: 0.1794 - accuracy: 0.9590\n",
      "Epoch 19/150\n",
      "512/512 [==============================] - 0s 50us/step - loss: 0.1579 - accuracy: 0.9668\n",
      "Epoch 20/150\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.1474 - accuracy: 0.9688\n",
      "Epoch 21/150\n",
      "512/512 [==============================] - 0s 58us/step - loss: 0.1333 - accuracy: 0.9668\n",
      "Epoch 22/150\n",
      "512/512 [==============================] - 0s 55us/step - loss: 0.1288 - accuracy: 0.9688\n",
      "Epoch 23/150\n",
      "512/512 [==============================] - 0s 50us/step - loss: 0.1202 - accuracy: 0.9707\n",
      "Epoch 24/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.1138 - accuracy: 0.9727\n",
      "Epoch 25/150\n",
      "512/512 [==============================] - 0s 56us/step - loss: 0.1048 - accuracy: 0.9727\n",
      "Epoch 26/150\n",
      "512/512 [==============================] - 0s 53us/step - loss: 0.1051 - accuracy: 0.9766\n",
      "Epoch 27/150\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.1005 - accuracy: 0.9746\n",
      "Epoch 28/150\n",
      "512/512 [==============================] - 0s 53us/step - loss: 0.0985 - accuracy: 0.9746\n",
      "Epoch 29/150\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.0930 - accuracy: 0.9805\n",
      "Epoch 30/150\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.0901 - accuracy: 0.9805\n",
      "Epoch 31/150\n",
      "512/512 [==============================] - 0s 53us/step - loss: 0.0878 - accuracy: 0.9805\n",
      "Epoch 32/150\n",
      "512/512 [==============================] - 0s 53us/step - loss: 0.0864 - accuracy: 0.9805\n",
      "Epoch 33/150\n",
      "512/512 [==============================] - 0s 56us/step - loss: 0.0827 - accuracy: 0.9824\n",
      "Epoch 34/150\n",
      "512/512 [==============================] - 0s 57us/step - loss: 0.0771 - accuracy: 0.9824\n",
      "Epoch 35/150\n",
      "512/512 [==============================] - 0s 52us/step - loss: 0.0766 - accuracy: 0.9824\n",
      "Epoch 36/150\n",
      "512/512 [==============================] - 0s 52us/step - loss: 0.0737 - accuracy: 0.9844\n",
      "Epoch 37/150\n",
      "512/512 [==============================] - 0s 55us/step - loss: 0.0754 - accuracy: 0.9844\n",
      "Epoch 38/150\n",
      "512/512 [==============================] - 0s 53us/step - loss: 0.0750 - accuracy: 0.9805\n",
      "Epoch 39/150\n",
      "512/512 [==============================] - 0s 52us/step - loss: 0.0731 - accuracy: 0.9824\n",
      "Epoch 40/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0747 - accuracy: 0.9844\n",
      "Epoch 41/150\n",
      "512/512 [==============================] - 0s 51us/step - loss: 0.0700 - accuracy: 0.9844\n",
      "Epoch 42/150\n",
      "512/512 [==============================] - 0s 50us/step - loss: 0.0725 - accuracy: 0.9863\n",
      "Epoch 43/150\n",
      "512/512 [==============================] - 0s 50us/step - loss: 0.0712 - accuracy: 0.9844\n",
      "Epoch 44/150\n",
      "512/512 [==============================] - 0s 53us/step - loss: 0.0738 - accuracy: 0.9844\n",
      "Epoch 45/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0685 - accuracy: 0.9863\n",
      "Epoch 46/150\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.0634 - accuracy: 0.9863\n",
      "Epoch 47/150\n",
      "512/512 [==============================] - 0s 49us/step - loss: 0.0681 - accuracy: 0.9844\n",
      "Epoch 48/150\n",
      "512/512 [==============================] - 0s 55us/step - loss: 0.0708 - accuracy: 0.9824\n",
      "Epoch 49/150\n",
      "512/512 [==============================] - 0s 51us/step - loss: 0.0609 - accuracy: 0.9863\n",
      "Epoch 50/150\n",
      "512/512 [==============================] - 0s 49us/step - loss: 0.0627 - accuracy: 0.9863\n",
      "Epoch 51/150\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.0670 - accuracy: 0.9844\n",
      "Epoch 52/150\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.0609 - accuracy: 0.9863\n",
      "Epoch 53/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0584 - accuracy: 0.9844\n",
      "Epoch 54/150\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.0631 - accuracy: 0.9844\n",
      "Epoch 55/150\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.0618 - accuracy: 0.9844\n",
      "Epoch 56/150\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.0601 - accuracy: 0.9863\n",
      "Epoch 57/150\n",
      "512/512 [==============================] - 0s 34us/step - loss: 0.0597 - accuracy: 0.9863\n",
      "Epoch 58/150\n",
      "512/512 [==============================] - 0s 52us/step - loss: 0.0617 - accuracy: 0.9844\n",
      "Epoch 59/150\n",
      "512/512 [==============================] - 0s 33us/step - loss: 0.0615 - accuracy: 0.9863\n",
      "Epoch 60/150\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.0603 - accuracy: 0.9844\n",
      "Epoch 61/150\n",
      "512/512 [==============================] - 0s 56us/step - loss: 0.0590 - accuracy: 0.9863\n",
      "Epoch 62/150\n",
      "512/512 [==============================] - 0s 54us/step - loss: 0.0573 - accuracy: 0.9863\n",
      "Epoch 63/150\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.0576 - accuracy: 0.9863\n",
      "Epoch 64/150\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.0562 - accuracy: 0.9863\n",
      "Epoch 65/150\n",
      "512/512 [==============================] - 0s 50us/step - loss: 0.0581 - accuracy: 0.9863\n",
      "Epoch 66/150\n",
      "512/512 [==============================] - 0s 49us/step - loss: 0.0567 - accuracy: 0.9844\n",
      "Epoch 67/150\n",
      "512/512 [==============================] - 0s 51us/step - loss: 0.0560 - accuracy: 0.9863\n",
      "Epoch 68/150\n",
      "512/512 [==============================] - 0s 54us/step - loss: 0.0561 - accuracy: 0.9863\n",
      "Epoch 69/150\n",
      "512/512 [==============================] - 0s 58us/step - loss: 0.0522 - accuracy: 0.9863\n",
      "Epoch 70/150\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.0553 - accuracy: 0.9844\n",
      "Epoch 71/150\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.0561 - accuracy: 0.9863\n",
      "Epoch 72/150\n",
      "512/512 [==============================] - 0s 49us/step - loss: 0.0564 - accuracy: 0.9844\n",
      "Epoch 73/150\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.0546 - accuracy: 0.9863\n",
      "Epoch 74/150\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.0536 - accuracy: 0.9863\n",
      "Epoch 75/150\n",
      "512/512 [==============================] - 0s 56us/step - loss: 0.0512 - accuracy: 0.9863\n",
      "Epoch 76/150\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.0561 - accuracy: 0.9863\n",
      "Epoch 77/150\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.0508 - accuracy: 0.9863\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 46us/step - loss: 0.0505 - accuracy: 0.9863\n",
      "Epoch 79/150\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.0523 - accuracy: 0.9863\n",
      "Epoch 80/150\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.0511 - accuracy: 0.9863\n",
      "Epoch 81/150\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.0498 - accuracy: 0.9863\n",
      "Epoch 82/150\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.0536 - accuracy: 0.9844\n",
      "Epoch 83/150\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.0540 - accuracy: 0.9863\n",
      "Epoch 84/150\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.0498 - accuracy: 0.9863\n",
      "Epoch 85/150\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.0473 - accuracy: 0.9863\n",
      "Epoch 86/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0476 - accuracy: 0.9883\n",
      "Epoch 87/150\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.0497 - accuracy: 0.9863\n",
      "Epoch 88/150\n",
      "512/512 [==============================] - 0s 55us/step - loss: 0.0520 - accuracy: 0.9883\n",
      "Epoch 89/150\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.0523 - accuracy: 0.9883\n",
      "Epoch 90/150\n",
      "512/512 [==============================] - 0s 35us/step - loss: 0.0483 - accuracy: 0.9883\n",
      "Epoch 91/150\n",
      "512/512 [==============================] - 0s 50us/step - loss: 0.0540 - accuracy: 0.9863\n",
      "Epoch 92/150\n",
      "512/512 [==============================] - 0s 66us/step - loss: 0.0457 - accuracy: 0.9902\n",
      "Epoch 93/150\n",
      "512/512 [==============================] - 0s 60us/step - loss: 0.0471 - accuracy: 0.9902\n",
      "Epoch 94/150\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.0463 - accuracy: 0.9902\n",
      "Epoch 95/150\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.0482 - accuracy: 0.9902\n",
      "Epoch 96/150\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.0533 - accuracy: 0.99 - 0s 44us/step - loss: 0.0476 - accuracy: 0.9883\n",
      "Epoch 97/150\n",
      "512/512 [==============================] - 0s 49us/step - loss: 0.0452 - accuracy: 0.9902\n",
      "Epoch 98/150\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.0473 - accuracy: 0.9883\n",
      "Epoch 99/150\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.0445 - accuracy: 0.9902\n",
      "Epoch 100/150\n",
      "512/512 [==============================] - 0s 50us/step - loss: 0.0438 - accuracy: 0.9902\n",
      "Epoch 101/150\n",
      "512/512 [==============================] - 0s 54us/step - loss: 0.0440 - accuracy: 0.9902\n",
      "Epoch 102/150\n",
      "512/512 [==============================] - 0s 54us/step - loss: 0.0477 - accuracy: 0.9902\n",
      "Epoch 103/150\n",
      "512/512 [==============================] - 0s 56us/step - loss: 0.0462 - accuracy: 0.9902\n",
      "Epoch 104/150\n",
      "512/512 [==============================] - 0s 54us/step - loss: 0.0436 - accuracy: 0.9902\n",
      "Epoch 105/150\n",
      "512/512 [==============================] - 0s 53us/step - loss: 0.0463 - accuracy: 0.9883\n",
      "Epoch 106/150\n",
      "512/512 [==============================] - 0s 54us/step - loss: 0.0457 - accuracy: 0.9902\n",
      "Epoch 107/150\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.0399 - accuracy: 0.9883\n",
      "Epoch 108/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0468 - accuracy: 0.9883\n",
      "Epoch 109/150\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.1058 - accuracy: 0.98 - 0s 35us/step - loss: 0.0500 - accuracy: 0.9922\n",
      "Epoch 110/150\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.0446 - accuracy: 0.9902\n",
      "Epoch 111/150\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.0430 - accuracy: 0.9902\n",
      "Epoch 112/150\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.0448 - accuracy: 0.9883\n",
      "Epoch 113/150\n",
      "512/512 [==============================] - 0s 49us/step - loss: 0.0443 - accuracy: 0.9902\n",
      "Epoch 114/150\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.0427 - accuracy: 0.9902\n",
      "Epoch 115/150\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.0417 - accuracy: 0.9922\n",
      "Epoch 116/150\n",
      "512/512 [==============================] - 0s 49us/step - loss: 0.0452 - accuracy: 0.9902\n",
      "Epoch 117/150\n",
      "512/512 [==============================] - 0s 53us/step - loss: 0.0395 - accuracy: 0.9922\n",
      "Epoch 118/150\n",
      "512/512 [==============================] - 0s 50us/step - loss: 0.0430 - accuracy: 0.9902\n",
      "Epoch 119/150\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.0417 - accuracy: 0.9902\n",
      "Epoch 120/150\n",
      "512/512 [==============================] - 0s 49us/step - loss: 0.0446 - accuracy: 0.9883\n",
      "Epoch 121/150\n",
      "512/512 [==============================] - 0s 49us/step - loss: 0.0448 - accuracy: 0.9863\n",
      "Epoch 122/150\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.0428 - accuracy: 0.9902\n",
      "Epoch 123/150\n",
      "512/512 [==============================] - 0s 52us/step - loss: 0.0423 - accuracy: 0.9922\n",
      "Epoch 124/150\n",
      "512/512 [==============================] - 0s 57us/step - loss: 0.0399 - accuracy: 0.9922\n",
      "Epoch 125/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0387 - accuracy: 0.9922\n",
      "Epoch 126/150\n",
      "512/512 [==============================] - 0s 53us/step - loss: 0.0383 - accuracy: 0.9922\n",
      "Epoch 127/150\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.0379 - accuracy: 0.9922\n",
      "Epoch 128/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0391 - accuracy: 0.9922\n",
      "Epoch 129/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0411 - accuracy: 0.9922\n",
      "Epoch 130/150\n",
      "512/512 [==============================] - 0s 51us/step - loss: 0.0398 - accuracy: 0.9902\n",
      "Epoch 131/150\n",
      "512/512 [==============================] - 0s 71us/step - loss: 0.0392 - accuracy: 0.9883\n",
      "Epoch 132/150\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.0416 - accuracy: 0.9902\n",
      "Epoch 133/150\n",
      "512/512 [==============================] - 0s 55us/step - loss: 0.0325 - accuracy: 0.9922\n",
      "Epoch 134/150\n",
      "512/512 [==============================] - 0s 58us/step - loss: 0.0414 - accuracy: 0.9902\n",
      "Epoch 135/150\n",
      "512/512 [==============================] - 0s 63us/step - loss: 0.0428 - accuracy: 0.9902\n",
      "Epoch 136/150\n",
      "512/512 [==============================] - 0s 55us/step - loss: 0.0368 - accuracy: 0.9922\n",
      "Epoch 137/150\n",
      "512/512 [==============================] - 0s 55us/step - loss: 0.0407 - accuracy: 0.9922\n",
      "Epoch 138/150\n",
      "512/512 [==============================] - 0s 61us/step - loss: 0.0402 - accuracy: 0.9902\n",
      "Epoch 139/150\n",
      "512/512 [==============================] - 0s 51us/step - loss: 0.0424 - accuracy: 0.9922\n",
      "Epoch 140/150\n",
      "512/512 [==============================] - 0s 58us/step - loss: 0.0424 - accuracy: 0.9902\n",
      "Epoch 141/150\n",
      "512/512 [==============================] - 0s 49us/step - loss: 0.0373 - accuracy: 0.9902\n",
      "Epoch 142/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0390 - accuracy: 0.9922\n",
      "Epoch 143/150\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.0384 - accuracy: 0.9922\n",
      "Epoch 144/150\n",
      "512/512 [==============================] - 0s 52us/step - loss: 0.0380 - accuracy: 0.9922\n",
      "Epoch 145/150\n",
      "512/512 [==============================] - 0s 60us/step - loss: 0.0391 - accuracy: 0.9902\n",
      "Epoch 146/150\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.0356 - accuracy: 0.9922\n",
      "Epoch 147/150\n",
      "512/512 [==============================] - 0s 50us/step - loss: 0.0399 - accuracy: 0.9922\n",
      "Epoch 148/150\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.0395 - accuracy: 0.9922\n",
      "Epoch 149/150\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.0346 - accuracy: 0.9922\n",
      "Epoch 150/150\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.0396 - accuracy: 0.9922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x281f7bc8b38>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, batch_size=100, nb_epoch=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x281f9671160>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our accuracy is 100.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Our accuracy is {}%\".format(((cm[0][0] + cm[1][1])/57)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
